# Cross-Modal Attention for Accurate Pedestrian Trajectory Prediction

# Overview
This repository contains the implementation of Cross-Modal Attention for Accurate Pedestrian Trajectory Prediction.

we propose a novel approach called Cross-Modal Attention Trajectory Prediction (CMATP) able to predict human paths based on observed trajectory and dynamic scene context. Our approach uses a bimodal transformer network to capture complex spatio-temporal interactions and incorporates both pedestrian trajectory data and contextual information.

Our approach includes a cross-attention module that integrates trajectory data with contextual information, allowing the network to capture the general temporal consistency of pedestrian movement. By using a convolutional model for feature extraction and a bimodal transformer, CMATP captures intricate spatio-temporal interactions, improving accuracy while maintaining the same computational complexity as using a single data type.

![Architecture_CMATP_Final_BMVC2023 drawio](https://github.com/MZ82020/CMATP/assets/94976539/00d6d619-6e66-4279-bfac-34afb999da80)


